{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US EPA Air Quality System API Example\n",
    "This illustrates how to request data from the US Environmental Protection Agency (EPA) Air Quality Service (AQS) API. This is a historical API and does not provide real-time air quality data. The [documentation](https://aqs.epa.gov/aqsweb/documents/data_api.html) for the API provides definitions of the different call parameter and examples of the various calls that can be made to the API.\n",
    "\n",
    "This notebook works systematically through example calls, requesting an API key, using 'list' to get various IDs and parameter values, and using 'daily summary' to get summary data that meets specific condistions. The notebook contains example function definitions that could be reused in other code. In general, the notebook explains each step along the way, referring back to possible output. Some of the explanations are tailored to the specific example requests of the API. Changing values to explore the results of the API is probably useful, but that will result in some explanations being out of sync with the outputs.\n",
    "\n",
    "The US EPA was created in the early 1970's. The EPA reports that they only started broad based monitoring with standardized quality assurance procedures in the 1980's. Many counties will have data starting somewhere between 1983 and 1988. However, some counties still do not have any air quality monitoring stations. The API helps resolve this by providing calls to search for monitoring stations and data using either station ids, or a county designation or a geographic bounding box. This example code provides examples of the county based and bounding box based API calls. Some [additional information on the Air Quality System can be found in the EPA FAQ](https://www.epa.gov/outdoor-air-quality-data/frequent-questions-about-airdata) on the system.\n",
    "\n",
    "The end goal is to get to some values that we might use for the Air Quality Index or AQI. You might see this reported on the news, most often around smog, but more frequently with regard to smoke. The AQI index is meant to tell us something about how healthy or clean the air is on any day. The AQI is actually a somewhat complext measure. When I started this example I looked up [how to calculate the AQI](https://www.airnow.gov/sites/default/files/2020-05/aqi-technical-assistance-document-sept2018.pdf) so that I would know roughly what goes into that value.\n",
    "\n",
    "\n",
    "## License\n",
    "This code was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.1 - September 5, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are standard python modules\n",
    "import json, time\n",
    "#\n",
    "#    The 'requests' module is a distribution module for making web requests.\n",
    "#\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#\n",
    "#    This is the root of all AQS API URLs\n",
    "#\n",
    "API_REQUEST_URL = 'https://aqs.epa.gov/data/api'\n",
    "\n",
    "#\n",
    "#    These are 'actions' we can ask the API to take or requests that we can make of the API\n",
    "#\n",
    "#    Sign-up request - generally only performed once - unless you lose your key\n",
    "API_ACTION_SIGNUP = '/signup?email={email}'\n",
    "#\n",
    "#    List actions provide information on API parameter values that are required by some other actions/requests\n",
    "API_ACTION_LIST_CLASSES = '/list/classes?email={email}&key={key}'\n",
    "API_ACTION_LIST_PARAMS = '/list/parametersByClass?email={email}&key={key}&pc={pclass}'\n",
    "API_ACTION_LIST_SITES = '/list/sitesByCounty?email={email}&key={key}&state={state}&county={county}'\n",
    "#\n",
    "#    Monitor actions are requests for monitoring stations that meet specific criteria\n",
    "API_ACTION_MONITORS_COUNTY = '/monitors/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_MONITORS_BOX = '/monitors/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    Summary actions are requests for summary data. These are for daily summaries\n",
    "API_ACTION_DAILY_SUMMARY_COUNTY = '/dailyData/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_DAILY_SUMMARY_BOX = '/dailyData/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    It is always nice to be respectful of a free data resource.\n",
    "#    We're going to observe a 100 requests per minute limit - which is fairly nice\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "#\n",
    "#\n",
    "#    This is a template that covers most of the parameters for the actions we might take, from the set of actions\n",
    "#    above. In the examples below, most of the time parameters can either be supplied as individual values to a\n",
    "#    function - or they can be set in a copy of the template and passed in with the template.\n",
    "# \n",
    "AQS_REQUEST_TEMPLATE = {\n",
    "    \"email\":      \"\",     \n",
    "    \"key\":        \"\",      \n",
    "    \"state\":      \"\",     # the two digit state FIPS # as a string\n",
    "    \"county\":     \"\",     # the three digit county FIPS # as a string\n",
    "    \"begin_date\": \"\",     # the start of a time window in YYYYMMDD format\n",
    "    \"end_date\":   \"\",     # the end of a time window in YYYYMMDD format, begin_date and end_date must be in the same year\n",
    "    \"minlat\":    0.0,\n",
    "    \"maxlat\":    0.0,\n",
    "    \"minlon\":    0.0,\n",
    "    \"maxlon\":    0.0,\n",
    "    \"param\":     \"\",     # a list of comma separated 5 digit codes, max 5 codes requested\n",
    "    \"pclass\":    \"\"      # parameter class is only used by the List calls\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will need to request an API key to access the API. I should test access to the API to understand whether I can get data for my city based on the US County where my city is located, or whether I need to create a geodetic bounding box to access station data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a sign-up request\n",
    "\n",
    "Before we can use the API, we need to request a key. We will use an email address to make the request. The EPA then sends a confirmation email link and a 'key' that we use for all other requests.\n",
    "\n",
    "We only need to sign-up once, unless we want to invalidate our current key (by getting a new key) or we lose our key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the sign-up request. The parameters are standardized so that this function definition matches\n",
    "#    all of the others. However, the easiest way to call this is to simply call this function with your preferred\n",
    "#    email address.\n",
    "#\n",
    "def request_signup(email_address = None,\n",
    "                   endpoint_url = API_REQUEST_URL, \n",
    "                   endpoint_action = API_ACTION_SIGNUP, \n",
    "                   request_template = AQS_REQUEST_TEMPLATE,\n",
    "                   headers = None):\n",
    "    \n",
    "    # Make sure we have a string - if you don't have access to this email addres, things might go badly for you\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address        \n",
    "    if not request_template['email']: \n",
    "        raise Exception(\"Must supply an email address to call 'request_signup()'\")\n",
    "    \n",
    "    # Compose the signup url - create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    A SIGNUP request is only to be done once, to request a key. A key is sent to that email address and needs to be confirmed with a click through\n",
    "#    This code should probably be commented out after you've made your key request to make sure you don't accidentally make a new sign-up request\n",
    "#\n",
    "#print(\"Requesting SIGNUP ...\")\n",
    "#response = request_signup(\"sagnik99@uw.edu\")\n",
    "#print(json.dumps(response,indent=4))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"sagnik99@uw.edu\"\n",
    "APIKEY= 'tealgoose54'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a list request\n",
    "Once you have a key, the next thing is to get information about the different types of air quality monitoring (sensors) and the different places where we might find air quality stations. The monitoring system is complex and changes all the time. The EPA implementation allows an API user to find changes to monitoring sites and sensors by making requests - maybe monthly, or daily. This API approach is probably better than having the EPA publish documentation that may be out of date as soon as it hits a web page. The one problem here is that some of the responses rely on jargon or terms-of-art. That is, one needs to know a bit about the way atmospheric sciece works to understand some of the terms. ... Good thing we can use the web to search for terms we don't know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the list request. There are several versions of the list request that only require email and key.\n",
    "#    This code sets the default action/requests to list the groups or parameter class descriptors. Having those descriptors \n",
    "#    allows one to request the individual (proprietary) 5 digit codes for individual air quality measures by using the\n",
    "#    param request. Some code in later cells will illustrate those requests.\n",
    "#\n",
    "def request_list_info(email_address = None, key = None,\n",
    "                      endpoint_url = API_REQUEST_URL, \n",
    "                      endpoint_action = API_ACTION_LIST_CLASSES, \n",
    "                      request_template = AQS_REQUEST_TEMPLATE,\n",
    "                      headers = None):\n",
    "    \n",
    "    #  Make sure we have email and key - at least\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    \n",
    "    # For the basic request we need an email address and a key\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_list_info()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_list_info()'\")\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"AIRNOW MAPS\",\n",
      "        \"value_represented\": \"The parameters represented on AirNow maps (88101, 88502, and 44201)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"ALL\",\n",
      "        \"value_represented\": \"Select all Parameters Available\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"AQI POLLUTANTS\",\n",
      "        \"value_represented\": \"Pollutants that have an AQI Defined\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CORE_HAPS\",\n",
      "        \"value_represented\": \"Urban Air Toxic Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CRITERIA\",\n",
      "        \"value_represented\": \"Criteria Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CSN DART\",\n",
      "        \"value_represented\": \"List of CSN speciation parameters to populate the STI DART tool\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"FORECAST\",\n",
      "        \"value_represented\": \"Parameters routinely extracted by AirNow (STI)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"HAPS\",\n",
      "        \"value_represented\": \"Hazardous Air Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE CARBON\",\n",
      "        \"value_represented\": \"IMPROVE Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE_SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters Measured at IMPROVE sites\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"MET\",\n",
      "        \"value_represented\": \"Meteorological Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS CORE HAPS\",\n",
      "        \"value_represented\": \"The core list of toxics of interest to the NATTS program.\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS REQUIRED\",\n",
      "        \"value_represented\": \"Required compounds to be collected in the National Air Toxics Network\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS\",\n",
      "        \"value_represented\": \"Photochemical Assessment Monitoring System\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS_VOC\",\n",
      "        \"value_represented\": \"Volatile Organic Compound subset of the PAMS Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM COARSE\",\n",
      "        \"value_represented\": \"PM between 2.5 and 10 micrometers\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM10 SPECIATION\",\n",
      "        \"value_represented\": \"PM10 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 CONT NONREF\",\n",
      "        \"value_represented\": \"PM2.5 Continuous, Nonreference Methods\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 MASS/QA\",\n",
      "        \"value_represented\": \"PM2.5 Mass and QA Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SCHOOL AIR TOXICS\",\n",
      "        \"value_represented\": \"School Air Toxics Program Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CARBON\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CATION/ANION\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Cation/Anion Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION METALS\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Metal Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP CARBONYL\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program Carbonyls\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP VOC\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program VOCs\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"VOC\",\n",
      "        \"value_represented\": \"Volatile organic compounds\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   The default should get us a list of the various groups or classes of sensors. These classes are user defined names for clustors of\n",
    "#   sensors that might be part of a package or default air quality sensing station. We need a class name to start getting down to the\n",
    "#   a sensor ID. Each sensor type has an ID number. We'll eventually need those ID numbers to be able to request values that come from\n",
    "#   that specific sensor.\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "\n",
    "response = request_list_info(request_template=request_data)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in getting to something that might be the Air Quality Index (AQI). You see this reported on the news - often around smog values, but also when there is smoke in the sky. The AQI is a complex measure of different gasses and of the particles in the air (dust, dirt, ash ...).\n",
    "\n",
    "From the list produced by our 'list/Classes' request above, it looks like there is a class of sensors called \"AQI POLLUTANTS\". Let's try to get a list of those specific sensors and see what we can get from those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Once we have a list of the classes or groups of possible sensors, we can find the sensor IDs that make up that class (group)\n",
    "#   The one that looks to be associated with the Air Quality Index is \"AQI POLLUTANTS\"\n",
    "#   We'll use that to make another list request.\n",
    "#\n",
    "AQI_PARAM_CLASS = \"AQI POLLUTANTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"42101\",\n",
      "        \"value_represented\": \"Carbon monoxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42401\",\n",
      "        \"value_represented\": \"Sulfur dioxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42602\",\n",
      "        \"value_represented\": \"Nitrogen dioxide (NO2)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"44201\",\n",
      "        \"value_represented\": \"Ozone\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"81102\",\n",
      "        \"value_represented\": \"PM10 Total 0-10um STP\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88101\",\n",
      "        \"value_represented\": \"PM2.5 - Local Conditions\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88502\",\n",
      "        \"value_represented\": \"Acceptable PM2.5 AQI & Speciation Mass\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   Structure a request to get the sensor IDs associated with the AQI\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['pclass'] = AQI_PARAM_CLASS  # here we specify that we want this 'pclass' or parameter classs\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_PARAMS)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have (above) a response containing a set of sensor ID numbers. The list should include the sensor numbers as well as a description or name for each sensor. \n",
    "\n",
    "The EPA AQS API has limits on some call parameters. Specifically, when we request data for sensors we can only specify a maximum of 5 different sensor values to return. This means we cannot get all of the Air Quality Index parameters in one request for data. We have to break it up.\n",
    "\n",
    "What I did below was to break the request into two logical groups, the AQI sensors that sample gasses and the AQI sensors that sample particles in the air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the set of sensor codes, now we can create a parameter list or 'param' value as defined by the AQS API spec.\n",
    "# It turns out that we want all of these measures for AQI, but we need to have two different param constants to get\n",
    "# all seven of the code types. We can only have a max of 5 sensors/values request per param.\n",
    "\n",
    "#   Gaseous AQI pollutants CO, SO2, NO2, and O2\n",
    "AQI_PARAMS_GASEOUS = \"42101,42401,42602,44201\"\n",
    "#   Particulate AQI pollutants PM10, PM2.5, and Acceptable PM2.5\n",
    "AQI_PARAMS_PARTICULATES = \"81102,88101,88502\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Air quality monitoring stations are located all over the US at different locations. We will need some sample locations to experiment with different locations to see what kinds of values come back from different sensor requests.\n",
    "\n",
    "This list includes the [FIPS](https://www.census.gov/library/reference/code-lists/ansi.html) number for the state and county as a 5 digit string. This format, the 5 digit string, is a 'old' format that is still widely used. There are new codes that may eventually be adopted for the US government information systems. But FIPS is currently what the AQS uses, so that's what is in the list as the constant.\n",
    "\n",
    "Used Tulare as assigned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use these two city locations in the examples below.\n",
    "CITY_LOCATIONS = {\n",
    "    'tulare' :       {'city'   : 'Tulare',\n",
    "                       'county' : 'Tulare',\n",
    "                       'state'  : 'California',\n",
    "                       'fips'   : '06107',\n",
    "                       'latlon' : [36.2714, -118.7770] }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our CITY_LOCATIONS constant we can now find which monitoring locations are nearby. One option is to use the county to define the area we're interest in. You can get the EPA to list their monitoring stations by county. You can also get a set of monitoring stations by using a bounding box of latitude, longitude points. For this example, we'll use the county approach. There is a bounding box example later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"0001\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0002\",\n",
      "        \"value_represented\": \"Sequoia NP-Lower Kaweah\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0003\",\n",
      "        \"value_represented\": \"Sequoia NP-Lodgepole Chlorinator\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0005\",\n",
      "        \"value_represented\": \"Sequoia & Kings Canyon NPs - Ash Mountain\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0006\",\n",
      "        \"value_represented\": \"Sequoia & Kings Canyon NPs - Lower Kaweah\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0007\",\n",
      "        \"value_represented\": \"Sequoia & Kings Canyon NPs - Grant Grove\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0008\",\n",
      "        \"value_represented\": \"Sequoia NP-Lookout Point Ranger Station\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0009\",\n",
      "        \"value_represented\": \"Sequoia & Kings Canyon NPs - Ash Mountain\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1001\",\n",
      "        \"value_represented\": \"Sequoia NP-Ash Mountain\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1002\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1003\",\n",
      "        \"value_represented\": \"Sequoia NP-Generals HWY\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"2001\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"2002\",\n",
      "        \"value_represented\": \"Visalia-Church\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"2003\",\n",
      "        \"value_represented\": \"Visalia-W. Ashland Avenue\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"2010\",\n",
      "        \"value_represented\": \"Porterville\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3000\",\n",
      "        \"value_represented\": \"Visalia-Airport\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3001\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4001\",\n",
      "        \"value_represented\": null\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  This list request should give us a list of all the monitoring stations in the county specified by the\n",
    "#  given city selected from the CITY_LOCATIONS dictionary\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['state'] = CITY_LOCATIONS['tulare']['fips'][:2]   # the first two digits (characters) of FIPS is the state code\n",
    "request_data['county'] = CITY_LOCATIONS['tulare']['fips'][2:]  # the last three digits (characters) of FIPS is the county code\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_SITES)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above response gives us a list of monitoring stations. Each monitoring station has a unique \"code\" which is a string number, and, sometimes, a description. The description seems to be something about where the monitoring station is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a daily summary request\n",
    "\n",
    "The function below is designed to encapsulate requests to the EPA AQS API. When calling the function one should create/copy a parameter template, then initialize that template with values that won't change with each call. Then on each call simply pass in the parameters that need to change, like date ranges.\n",
    "\n",
    "Another function below provides an example of extracting values and restructuring the response to make it a little more usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the daily summary request. Daily summary provides a daily summary value for each sensor being requested\n",
    "#    from the start date to the end date. \n",
    "#\n",
    "#    Like the two other functions, this can be called with a mixture of a defined parameter dictionary, or with function\n",
    "#    parameters. If function parameters are provided, those take precedence over any parameters from the request template.\n",
    "#\n",
    "def request_daily_summary(email_address = None, key = None, param=None,\n",
    "                          begin_date = None, end_date = None, fips = None,\n",
    "                          endpoint_url = API_REQUEST_URL, \n",
    "                          endpoint_action = API_ACTION_DAILY_SUMMARY_COUNTY, \n",
    "                          request_template = AQS_REQUEST_TEMPLATE,\n",
    "                          headers = None):\n",
    "    \n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    if param:\n",
    "        request_template['param'] = param\n",
    "    if begin_date:\n",
    "        request_template['begin_date'] = begin_date\n",
    "    if end_date:\n",
    "        request_template['end_date'] = end_date\n",
    "    if fips and len(fips)==5:\n",
    "        request_template['state'] = fips[:2]\n",
    "        request_template['county'] = fips[2:]            \n",
    "\n",
    "    # Make sure there are values that allow us to make a call - these are always required\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_daily_summary()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_daily_summary()'\")\n",
    "    if not request_template['param']: \n",
    "        raise Exception(\"Must supply param values to call 'request_daily_summary()'\")\n",
    "    if not request_template['begin_date']: \n",
    "        raise Exception(\"Must supply a begin_date to call 'request_daily_summary()'\")\n",
    "    if not request_template['end_date']: \n",
    "        raise Exception(\"Must supply an end_date to call 'request_daily_summary()'\")\n",
    "    # Note we're not validating FIPS fields because not all of the daily summary actions require the FIPS numbers\n",
    "        \n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form of the daily summary response is a bit verbose with lots of repeated values. What we'll do is create a data structure that relies on a hierarchical context to summarize the data.\n",
    "\n",
    "The two responses show that not every monitoring site produces values. As well, it looks like the monitoring sites only produce values for particulates and not for gaseous pollutants.\n",
    "\n",
    "The next function takes the response and a set of fields that should be extracted for their data values. The code assumes those fields are available. If there are missing values something could certainly go wrong. The function creates a summary for each monitoring site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This is a list of field names - data - that will be extracted from each record\n",
    "#\n",
    "EXTRACTION_FIELDS = ['sample_duration','observation_count','arithmetic_mean','aqi']\n",
    "\n",
    "#\n",
    "#    The function creates a summary record\n",
    "def extract_summary_from_response(r=None, fields=EXTRACTION_FIELDS):\n",
    "    ## the result will be structured around monitoring site, parameter, and then date\n",
    "    result = dict()\n",
    "    data = r[\"Data\"]\n",
    "    for record in data:\n",
    "        # make sure the record is set up\n",
    "        site = record['site_number']\n",
    "        param = record['parameter_code']\n",
    "        #date = record['date_local']    # this version keeps the respnse value YYYY-\n",
    "        date = record['date_local'].replace('-','') # this puts it in YYYYMMDD format\n",
    "        if site not in result:\n",
    "            result[site] = dict()\n",
    "            result[site]['local_site_name'] = record['local_site_name']\n",
    "            result[site]['site_address'] = record['site_address']\n",
    "            result[site]['state'] = record['state']\n",
    "            result[site]['county'] = record['county']\n",
    "            result[site]['city'] = record['city']\n",
    "            result[site]['pollutant_type'] = dict()\n",
    "        if param not in result[site]['pollutant_type']:\n",
    "            result[site]['pollutant_type'][param] = dict()\n",
    "            result[site]['pollutant_type'][param]['parameter_name'] = record['parameter']\n",
    "            result[site]['pollutant_type'][param]['units_of_measure'] = record['units_of_measure']\n",
    "            result[site]['pollutant_type'][param]['method'] = record['method']\n",
    "            result[site]['pollutant_type'][param]['data'] = dict()\n",
    "        if date not in result[site]['pollutant_type'][param]['data']:\n",
    "            result[site]['pollutant_type'][param]['data'][date] = list()\n",
    "        \n",
    "        # now extract the specified fields\n",
    "        extract = dict()\n",
    "        for k in fields:\n",
    "            if str(k) in record:\n",
    "                extract[str(k)] = record[k]\n",
    "            else:\n",
    "                # this makes sure we always have the requested fields, even if\n",
    "                # we have a missing value for a given day/month\n",
    "                extract[str(k)] = None\n",
    "        \n",
    "        # add this extraction to the list for the day\n",
    "        result[site]['pollutant_type'][param]['data'][date].append(extract)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell uses the functions defined above and extracts data from 1963 to 2023. A loop is used as during one API call only 1 years of data can be accessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for 1963.\n",
      "No data available for 1964.\n",
      "No data available for 1965.\n",
      "No data available for 1966.\n",
      "No data available for 1967.\n",
      "No data available for 1968.\n",
      "No data available for 1969.\n",
      "No data available for 1970.\n",
      "No data available for 1971.\n",
      "No data available for 1972.\n",
      "No data available for 1973.\n",
      "No data available for 1974.\n",
      "No data available for 1975.\n",
      "No data available for 1976.\n",
      "No data available for 1977.\n",
      "No data available for 1978.\n",
      "No data available for 1979.\n",
      "No data available for 1980.\n",
      "No data available for 1981.\n",
      "No data available for 1982.\n",
      "No data available for 1983.\n",
      "No data available for 1984.\n",
      "No data available for 1985.\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "request_data['state'] = CITY_LOCATIONS['tulare']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['tulare']['fips'][2:]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "all_particulate_data = []\n",
    "\n",
    "# Define the request template and base URL\n",
    "request_template = \"YOUR_REQUEST_TEMPLATE_HERE\"\n",
    "base_url = \"YOUR_BASE_URL_HERE\"\n",
    "\n",
    "# Define the years you want to retrieve data for\n",
    "start_year = 1963\n",
    "end_year = 2023\n",
    "\n",
    "# Loop through the years and request daily summary data\n",
    "for year in range(start_year, end_year + 1):\n",
    "    begin_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    # Make the request for the current year\n",
    "    particulate_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    \n",
    "    # Check the response and append data to the list\n",
    "    if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        #all_gaseous_data.extend(gaseous_aqi['Data'])\n",
    "        extract_particulate = extract_summary_from_response(particulate_aqi)\n",
    "        #print(\"Summary of particulate extraction ...\")\n",
    "        #print(json.dumps(extract_gaseous,indent=4))\n",
    "        all_particulate_data.append(extract_particulate)\n",
    "        \n",
    "    elif particulate_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"No data available for {year}.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error in retrieving data for {year}.\")\n",
    "\n",
    "# # Print or process the collected data\n",
    "# print(\"Response for the particulate pollutants ...\")\n",
    "# print(json.dumps(all_particulate_data, indent=4))\n",
    "\n",
    "# Now, the all_gaseous_data list contains data for each year from 1963 to 2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell takes our raw data and stores it as a JSON file in our computer for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been written to ../intermediate data/particulate_data.json with an indentation of 4.\n"
     ]
    }
   ],
   "source": [
    "# Define the output file name\n",
    "output_file = \"../intermediate data/particulate_data.json\"\n",
    "\n",
    "# Write the JSON data to the text file with an indentation of 4\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(all_particulate_data, file, indent=4)\n",
    "\n",
    "print(f\"JSON data has been written to {output_file} with an indentation of 4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below two cells the same work is being done as in the above two cells. First aqi data is extracted for gaseous for 1963 to 2023 and then raw file is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for 1963.\n",
      "No data available for 1964.\n",
      "No data available for 1965.\n",
      "No data available for 1966.\n",
      "No data available for 1967.\n",
      "No data available for 1968.\n",
      "No data available for 1969.\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "request_data['state'] = CITY_LOCATIONS['tulare']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['tulare']['fips'][2:]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "all_gaseous_data = []\n",
    "\n",
    "# Define the request template and base URL\n",
    "request_template = \"YOUR_REQUEST_TEMPLATE_HERE\"\n",
    "base_url = \"YOUR_BASE_URL_HERE\"\n",
    "\n",
    "# Define the years you want to retrieve data for\n",
    "start_year = 1963\n",
    "end_year = 2023\n",
    "\n",
    "# Loop through the years and request daily summary data\n",
    "for year in range(start_year, end_year + 1):\n",
    "    begin_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    # Make the request for the current year\n",
    "    gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    \n",
    "    # Check the response and append data to the list\n",
    "    if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        #all_gaseous_data.extend(gaseous_aqi['Data'])\n",
    "        extract_gaseous = extract_summary_from_response(gaseous_aqi)\n",
    "        #print(\"Summary of particulate extraction ...\")\n",
    "        #print(json.dumps(extract_gaseous,indent=4))\n",
    "        all_gaseous_data.append(extract_gaseous)\n",
    "        \n",
    "    elif gaseous_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"No data available for {year}.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error in retrieving data for {year}.\")\n",
    "\n",
    "# # Print or process the collected data\n",
    "# print(\"Response for the gaseous pollutants ...\")\n",
    "# print(json.dumps(all_gaseous_data, indent=4))\n",
    "\n",
    "# Now, the all_gaseous_data list contains data for each year from 1963 to 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been written to ../intermediate data/gaseous_data.json with an indentation of 4.\n"
     ]
    }
   ],
   "source": [
    "# Define the output file name\n",
    "output_file = \"../intermediate data/gaseous_data.json\"\n",
    "\n",
    "# Write the JSON data to the text file with an indentation of 4\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(all_gaseous_data, file, indent=4)\n",
    "\n",
    "print(f\"JSON data has been written to {output_file} with an indentation of 4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function takes as input the raw aqi list of dicts and returns processed output with aqi, sample_duration and the date for which it was taken. \n",
    "\n",
    "After this extract_aqi() is used on both gaseous and particulate data. \n",
    "\n",
    "Once the data is extracted it is further filtered down and converted to the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aqi(data, dynamic_keys=None):\n",
    "    if dynamic_keys is None:\n",
    "        dynamic_keys = []\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    for key, value in data.items():\n",
    "        current_keys = dynamic_keys + [key]\n",
    "\n",
    "        if isinstance(value, dict):\n",
    "            extracted_data.extend(extract_aqi(value, current_keys))\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    aqi = item.get(\"aqi\")\n",
    "                    sample_duration = item.get(\"sample_duration\")\n",
    "                    if aqi is not None:\n",
    "                        extracted_data.append({\"keys\": current_keys,\"sample_duration\": sample_duration, \"aqi\": aqi})\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the extracted data\n",
    "extracted_data_gaseous = []\n",
    "\n",
    "# Iterate through the list of datasets\n",
    "for dataset in all_gaseous_data:\n",
    "    extracted_data_gaseous.extend(extract_aqi(dataset))\n",
    "\n",
    "# Print or further process the extracted data\n",
    "for entry in extracted_data_gaseous:\n",
    "    keys = \" > \".join(entry[\"keys\"])\n",
    "    aqi = entry[\"aqi\"]\n",
    "    sample = entry['sample_duration']\n",
    "#     print(f\"Keys: {keys}, AQI: {aqi} , SAMPLE: {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the extracted data\n",
    "extracted_data_particulate = []\n",
    "\n",
    "# Iterate through the list of datasets\n",
    "for dataset in all_particulate_data:\n",
    "    extracted_data_particulate.extend(extract_aqi(dataset))\n",
    "\n",
    "# Print or further process the extracted data\n",
    "for entry in extracted_data_particulate:\n",
    "    keys = \" > \".join(entry[\"keys\"])\n",
    "    aqi = entry[\"aqi\"]\n",
    "    sample = entry['sample_duration']\n",
    "#     print(f\"Keys: {keys}, AQI: {aqi} , SAMPLE: {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data_particulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant information and create a new list of dictionaries\n",
    "formatted_data = []\n",
    "\n",
    "for entry in extracted_data_particulate:\n",
    "    keys = entry['keys']\n",
    "    date = keys[-1]\n",
    "    aqi = entry['aqi']\n",
    "    sample_duration = entry['sample_duration']\n",
    "    pollutant_type = keys[-3]\n",
    "\n",
    "    formatted_data.append({'Date': date, 'AQI': aqi, 'Sample_Duration': sample_duration, 'Pollutant_Type': pollutant_type})\n",
    "\n",
    "# Create a DataFrame from the formatted data\n",
    "particulate_df = pd.DataFrame(formatted_data)\n",
    "\n",
    "# Convert the 'Date' column to a datetime format\n",
    "particulate_df['Date'] = pd.to_datetime(particulate_df['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>Sample_Duration</th>\n",
       "      <th>Pollutant_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-11-04</td>\n",
       "      <td>87</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-11-10</td>\n",
       "      <td>79</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-11-16</td>\n",
       "      <td>87</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-11-22</td>\n",
       "      <td>57</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-11-28</td>\n",
       "      <td>69</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AQI Sample_Duration Pollutant_Type\n",
       "0 1986-11-04   87         24 HOUR          81102\n",
       "1 1986-11-10   79         24 HOUR          81102\n",
       "2 1986-11-16   87         24 HOUR          81102\n",
       "3 1986-11-22   57         24 HOUR          81102\n",
       "4 1986-11-28   69         24 HOUR          81102"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particulate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant information and create a new list of dictionaries\n",
    "formatted_data = []\n",
    "\n",
    "for entry in extracted_data_gaseous:\n",
    "    keys = entry['keys']\n",
    "    date = keys[-1]\n",
    "    aqi = entry['aqi']\n",
    "    sample_duration = entry['sample_duration']\n",
    "    pollutant_type = keys[-3]\n",
    "\n",
    "    formatted_data.append({'Date': date, 'AQI': aqi, 'Sample_Duration': sample_duration, 'Pollutant_Type': pollutant_type})\n",
    "\n",
    "# Create a DataFrame from the formatted data\n",
    "gaseous_df = pd.DataFrame(formatted_data)\n",
    "\n",
    "# Convert the 'Date' column to a datetime format\n",
    "gaseous_df['Date'] = pd.to_datetime(gaseous_df['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>Sample_Duration</th>\n",
       "      <th>Pollutant_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-03-19</td>\n",
       "      <td>38</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-03-19</td>\n",
       "      <td>38</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-03-18</td>\n",
       "      <td>47</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-03-18</td>\n",
       "      <td>47</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-03-20</td>\n",
       "      <td>57</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AQI Sample_Duration Pollutant_Type\n",
       "0 1970-03-19   38          1 HOUR          42602\n",
       "1 1970-03-19   38          1 HOUR          42602\n",
       "2 1970-03-18   47          1 HOUR          42602\n",
       "3 1970-03-18   47          1 HOUR          42602\n",
       "4 1970-03-20   57          1 HOUR          42602"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaseous_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both the dataframes are saved so thtey can be used later easily and time can be saved\n",
    "gaseous_df.to_csv(\"../intermediate data/gaseous_aqi_data_processed.csv\")\n",
    "particulate_df.to_csv(\"../intermediate data/particulate_aqi_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, the primary objective is to combine and analyze air quality data from two separate DataFrames, particulate_df and gaseous_df. The code begins by creating copies of these DataFrames and removing certain columns that are not required for the analysis. Next, the code groups the data by date, calculates the average air quality measurements for each date, and combines the results into a single DataFrame. The code then computes a unified Air Quality Index (AQI) from the individual gaseous and particulate AQI values, filling in missing values as needed. Afterward, the code extracts the year from the 'Date' column, groups the data by year, and calculates the mean AQI for each year. The result is stored in the aqi_df DataFrame, providing a summary of annual average AQI values for further analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "particulate_df1 = particulate_df.copy()\n",
    "gaseous_df1 = gaseous_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "particulate_df1 = particulate_df1.drop(['Sample_Duration', 'Pollutant_Type'], axis=1)\n",
    "gaseous_df1 = gaseous_df1.drop(['Sample_Duration', 'Pollutant_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Date' and calculate the mean for each group\n",
    "particulate_avg_df = particulate_df1.groupby('Date', as_index=False).mean()\n",
    "gaseous_avg_df = gaseous_df1.groupby('Date', as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on 'Date' and take the maximum AQI or fill with values from either DataFrame\n",
    "combined_df = gaseous_avg_df.merge(particulate_avg_df, on='Date', how='outer', suffixes=('_gaseous', '_particulate'))\n",
    "combined_df['AQI'] = combined_df[['AQI_gaseous', 'AQI_particulate']].max(axis=1)\n",
    "combined_df['AQI'].fillna(combined_df['AQI_gaseous'].combine_first(combined_df['AQI_particulate']), inplace=True)\n",
    "combined_df.drop(columns=['AQI_gaseous', 'AQI_particulate'], inplace=True)\n",
    "# Extract the year from the 'Date' column\n",
    "combined_df['Year'] = combined_df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Year' and calculate the mean AQI for each year\n",
    "aqi_df = combined_df.groupby('Year')['AQI'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>41.989655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971</td>\n",
       "      <td>47.299543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972</td>\n",
       "      <td>39.757741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973</td>\n",
       "      <td>43.811872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1974</td>\n",
       "      <td>40.801826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year        AQI\n",
       "0  1970  41.989655\n",
       "1  1971  47.299543\n",
       "2  1972  39.757741\n",
       "3  1973  43.811872\n",
       "4  1974  40.801826"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying what aqi_df looks like\n",
    "aqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aqi_df dataframe\n",
    "aqi_df.to_csv(\"../intermediate data/final_aqi_each_year.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
